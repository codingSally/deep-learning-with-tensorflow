{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性模型最大的特点是：任意线性模型的组合仍然还是线性模型\n",
    "# 激活函数用来实现去线性化\n",
    "# 常用激活函数有：Relu函数、sigmoid函数、tanh函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类问题：交叉熵(Cross Entropy)  -- 用来刻画两个概率分布之间的距离\n",
    "# 回归问题：MSE(Mean Squared error)\n",
    "# 自定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 神经网络优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过反向传播算法和梯度下降算法来调整神经网络中参数的取值\n",
    "# 梯度下降算法主要用于优化单个参数的取值\n",
    "# 反向传播算法给出了一个高效的方式在所有参数上使用梯度下降算法，从而使神经网络模型在训练数据上的损失函数尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 神经网络的进一步优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率的设置  -- 不宜过大或过小【注意思考为什么？】\n",
    "# 过拟合问题 -- 正则化【注意思考为什么？】\n",
    "# 滑动平均模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 正则化\n",
    "# 正则化的思想就是在损失函数中加入刻画模型复杂度的指标\n",
    "# 假设用于刻画模型在训练数据上表现的损失函数为J(theta),那么优化时不是直接优化J(theta),而是优化J(theta) + lambda*R(w)\n",
    "# 其中R(w)刻画的是模型的复杂度，而lambda表示模型复杂损失在总损失中的比例\n",
    "# L1正则化、L2正则化、也可以L1 和 L2同时使用\n",
    "# L1 和 L2 的区别\n",
    "## a. 首先，L1正则化会让参数变的更稀疏，[即更多参数为0]\n",
    "## b. 其次，L1正则化的计算公式不可导，而L2正则化公式可导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正则化代码示例\n",
    "import tensorflow as tf\n",
    "\n",
    "# 获取一层神经网络边上的权重，并将这个权重的L2正则化损失加入名称为losses的集合中\n",
    "def get_weight(shape, lambda):\n",
    "    # 生成一个变量\n",
    "    var = tf.Variable(tf.random_normal_initializer(shape, dtype= tf.float32))\n",
    "    # add_to_collection函数将这个新生成变量的L2正则化损失项加入集合\n",
    "    # 这个函数的第一个参数‘losses’是集合的名字，第二个参数是要加入这个集合的内容\n",
    "    tf.add_to_collection(\n",
    "        'losses', tf.contrib.layers.l2_regularizer(lambda)(var))\n",
    "    # 返回生成的变量\n",
    "    \n",
    "x = tf.placeholder(tf.float32, shape = (None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape = (None, 1))\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# 定义了每一层网络中节点的个数\n",
    "layer_dimension = [2, 10, 10, 10, 1]\n",
    "# 神经网络的层数\n",
    "n_layers = len(layer_dimension)\n",
    "\n",
    "# 这个变量维护前向传播时最深层的节点，开始的时候就是输入层\n",
    "cur_layer = x\n",
    "# 当前层的节点个数\n",
    "in_dimension = layer_dimension[0]\n",
    "\n",
    "# 通过一个循环来生成5层全连接的神经网络结构\n",
    "for i in range(1, n_layers):\n",
    "    # layer_dimension[i] 为下一层的节点个数\n",
    "    out_dimension = layer_dimension[i]\n",
    "    # 生成当前层中权重的变量，并将这个变量的L2正则化损失加入计算图上的集合\n",
    "    weight = get_weight([in_dimension, out_dimension], 0.001)\n",
    "    bias = tf.Variable(tf.constant(0.1, shape = [out_dimension]))\n",
    "    # 使用ReLU激活函数\n",
    "    cur_layer = tf.nn.relu(tf.matmul(cur_layer, weight) + bias)\n",
    "    # 进入下一层之前将下一层的节点个数更新为当前层节点个数\n",
    "    in_dimension = layer_dimension[i]\n",
    "    \n",
    "# 在定义神经网络前向传播的同时已经将所有L2正则化损失加入了图上的集合\n",
    "# 在这里只需要计算刻画模型在训练数据上表现的损失函数\n",
    "mse_loss = tf.reduce_mean(tf.square(y_ - cur_layer))\n",
    "\n",
    "# 将均方误差损失函数加入损失集合\n",
    "tf.add_to_collection('losses', mse_loss)\n",
    "\n",
    "# get_collection 返回一个列表，这个列表是所有这个集合中的元素。在这个样例中，\n",
    "# 这些元素就是损失函数的不同部分，将他们加起来就可以得到最终的损失函数\n",
    "loss = tf.add_n(tf.get_collection('losses'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 滑动平均模型\n",
    "# 作用：使模型在测试数据集上更健壮\n",
    "# 方法：提供一个衰减率，用于控制模型更新的速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 滑动平均模型代码示例\n",
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个变量用于计算滑动平均，这个变量的初始值为0.注意这里手动指定了变量的类型为tf.float32\n",
    "# 因为所有需要计算滑动评剧嗯的变量必须时实数型\n",
    "v1 = tf.Variable(0, dtype = tf.float32)\n",
    "# 这里step变量模拟神经网络中迭代的轮数，可以用于动态控制衰减率\n",
    "step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# 定义一个滑动平均的类(class).初始化时给定了衰减率(0.99)和控制衰减率的变量step\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "# 定义一个更新变量滑动平均的操作。这里需要给定一个列表，每次执行这个操作时，\n",
    "# 这个列表中的变量都会被更新\n",
    "maintain_averages_op = ema.apply([v1])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化所有变量\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # 通过ema.average(v1)获取滑动平均之后变量的取值。在初始化之后变量v1的值和v1的滑动平均都为0\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    # 更新变量v1的值到5\n",
    "    sess.run(tf.asssign(v1, 5))\n",
    "    # 更新V1的滑动平均值，衰减率为min(0.99, (1+step) / (10+step) = 0.1) = 0.1\n",
    "    # 所以v1的滑动平均会被更新为0.1 * 0 + 0.9 * 5 = 4.5\n",
    "    sess.run(maintain_averages_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    # 更新step的值为10000\n",
    "    sess.run(tf.asssign(step, 10000))\n",
    "    # 更新v1的值为10\n",
    "    sess.run(tf.asssign(v1, 10))\n",
    "    # 更新v1的滑动平均值。衰减率为min(0.99, (1+step)/(10+step) = 0.99) = 0.99\n",
    "    # 所以v1的滑动平均会被更新为0.99 * 4.5 + 0.01 * 10 = 4.555\n",
    "    print(sess.run([v1, ems.average(v1)]))\n",
    "    # 输出[10.0, 4.5549998]\n",
    "    \n",
    "    # 再次更新滑动平均值，得到的新滑动平均值为0.99 * 4.555 + 0.01 * 10 = 4.60945\n",
    "    sess.run(maintain_averages_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    # 输出[10.0, 4.6094499]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
